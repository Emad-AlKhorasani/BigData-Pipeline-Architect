project: "Kaggle_Live_E-commerce_Data_Pipeline"
nodes:
  - id: "Kaggle_Cloud"
    name: "Kaggle API (Raw Source)"
    type: "Ingestion"
  - id: "Python_Handler"
    name: "Python (KaggleHub Wrapper)"
    type: "Processing"
  - id: "Kafka_Stream"
    name: "Apache Kafka (Message Queue)"
    type: "Ingestion"
  - id: "Spark_Engine"
    name: "Apache Spark (Transformation)"
    type: "Processing"
  - id: "HDFS_Data"
    name: "HDFS (Persistence Layer)"
    type: "Storage"
  - id: "Hive_Warehouse"
    name: "Apache Hive (Structured DB)"
    type: "Storage"
  - id: "Visualization"
    name: "Metabase/Tableau (BI)"
    type: "Visualization"

flows:
  - from: "Kaggle_Cloud"
    to: "Python_Handler"
    label: "Fetch Dataset"
  - from: "Python_Handler"
    to: "Kafka_Stream"
    label: "Stream Data"
  - from: "Kafka_Stream"
    to: "Spark_Engine"
    label: "Batch Processing"
  - from: "Spark_Engine"
    to: "HDFS_Data"
    label: "Save Parquet"
  - from: "HDFS_Data"
    to: "Hive_Warehouse"
    label: "External Table"
  - from: "Hive_Warehouse"
    to: "Visualization"
    label: "Dashboard Query"
